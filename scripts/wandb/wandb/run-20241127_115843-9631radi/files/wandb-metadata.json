{
  "os":  "Windows-11-10.0.22631-SP0",
  "python":  "3.12.3",
  "startedAt":  "2024-11-27T00:58:43.086058Z",
  "args":  [
    "--model_name",
    "Qwen/Qwen2.5-0.5B-Instruct",
    "--dataset_path",
    "d:/llm/fine-tune/qlora_pipeline\\data\\physics_qa.json",
    "--output_dir",
    "d:/llm/fine-tune/qlora_pipeline\\models\\run_2024-27-11_1158",
    "--input_column",
    "input",
    "--target_column",
    "output",
    "--max_samples",
    "1000",
    "--max_length",
    "2048",
    "--num_train_epochs",
    "3",
    "--per_device_train_batch_size",
    "4",
    "--gradient_accumulation_steps",
    "4",
    "--learning_rate",
    "2e-4",
    "--weight_decay",
    "0.001",
    "--warmup_ratio",
    "0.03",
    "--lora_r",
    "8",
    "--lora_alpha",
    "32",
    "--lora_dropout",
    "0.1",
    "--seed",
    "42",
    "--logging_steps",
    "10",
    "--save_steps",
    "50",
    "--save_total_limit",
    "3",
    "--bits",
    "4",
    "--double_quant",
    "true",
    "--quant_type",
    "nf4",
    "--prompt_template_type",
    "qwen",
    "--wandb_project",
    "qwen-qlora",
    "--trust_remote_code",
    "true",
    "--report_to",
    "wandb"
  ],
  "program":  "D:\\llm\\fine-tune\\qlora_pipeline\\scripts\\..\\train.py",
  "codePath":  "..\\train.py",
  "email":  "long8244557@gmail.com",
  "root":  "wandb",
  "host":  "MSI",
  "username":  "long8",
  "executable":  "D:\\anaconda3\\python.exe",
  "codePathLocal":  "..\\train.py"
}